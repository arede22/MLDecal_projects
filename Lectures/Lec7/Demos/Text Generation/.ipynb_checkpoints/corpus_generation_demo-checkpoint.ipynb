{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 1115390\n",
      "\n",
      "\n",
      "\n",
      "First 100 characters:\n",
      "\n",
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'A', 'l', 'l', ':', '\\n', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'Y', 'o', 'u']\n"
     ]
    }
   ],
   "source": [
    "#List of all possible characters\n",
    "CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" \\\n",
    "        + \"!\\\"#$%&\\'()*+,-./:;â€”<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\"\n",
    "\n",
    "#Will contain raw characters from the corpus\n",
    "corpus = []\n",
    "with open('shakespeare.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.strip():\n",
    "            corpus.append(char)\n",
    "        corpus.append('\\n')\n",
    "\n",
    "print(\"Total number of characters:\", len(corpus))\n",
    "print(\"\\n\\n\")\n",
    "print(\"First 100 characters:\\n\")\n",
    "print(corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of distinct chars: 101\n"
     ]
    }
   ],
   "source": [
    "#Map from character to its corresponding index\n",
    "char2idx = {char : i for i, char in enumerate(CHARS)}\n",
    "#Map from index to its corresponding character\n",
    "idx2char = {i : char for i, char in enumerate(CHARS)}\n",
    "\n",
    "NUM_CHARS = len(char2idx)\n",
    "print(\"Total number of distinct chars:\", NUM_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus with indices:\n",
      "[41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 37, 14, 15, 24, 27, 14, 95, 32, 14, 95, 25, 27, 24, 12, 14, 14, 13, 95, 10, 23, 34, 95, 15, 30, 27, 29, 17, 14, 27, 73, 95, 17, 14, 10, 27, 95, 22, 14, 95, 28, 25, 14, 10, 20, 75, 97, 97, 36, 21, 21, 77, 97, 54, 25, 14, 10, 20, 73, 95, 28, 25, 14, 10, 20, 75, 97, 97, 41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 60, 24, 30]\n",
      "\n",
      "Size of dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "#Corpus but with indices as opposed to characters\n",
    "corpus_with_indices = [char2idx[char] for char in corpus]\n",
    "\n",
    "print(\"Corpus with indices:\")\n",
    "print(corpus_with_indices[:100])\n",
    "\n",
    "SIZE_OF_SNIPPET = 250\n",
    "#Dataset will contain 2000 random 250 character blocks from corpus\n",
    "dataset = []\n",
    "for _ in range(2000):\n",
    "    \n",
    "    snipped_start = np.random.randint(0, len(corpus_with_indices) - SIZE_OF_SNIPPET)\n",
    "    snipped = corpus_with_indices[snipped_start:snipped_start + SIZE_OF_SNIPPET]\n",
    "    \n",
    "    dataset.append((\n",
    "        torch.LongTensor(snipped[:-1]),\n",
    "        torch.LongTensor(snipped[1:])\n",
    "    ))\n",
    "\n",
    "print(\"\\nSize of dataset:\", len(dataset))\n",
    "\n",
    "X = torch.stack([xy[0] for xy in dataset])\n",
    "Y = torch.stack([xy[1] for xy in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "class ShakespeareGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #Size of embedding used to represent characters\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        #Size of hidden and cell state within LSTM\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #Embedding module: Maps character indices to dense vector representations\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=NUM_CHARS,\n",
    "            embedding_dim=self.embedding_size\n",
    "        )\n",
    "        \n",
    "        #LSTM module to be used for character generation\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size\n",
    "        )\n",
    "        \n",
    "        #Linear mapping to be used to go from LSTM outputs to character predictions\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=NUM_CHARS\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batched_inputs):\n",
    "        #Number of character blocks to be considered simultaneously\n",
    "        batch_size = batched_inputs.shape[1]\n",
    "        #Hidden and Cell state initialized to all ones\n",
    "        h, c = self.get_initial_hc(batch_size)\n",
    "        #Character block length\n",
    "        seq_len = batched_inputs.shape[0]\n",
    "\n",
    "        #Embeddings from raw character inputs\n",
    "        embeddings = self.embedding(batched_inputs)\n",
    "        \n",
    "        #Outputs and final state of LSTM after processing embedddings\n",
    "        outputs, (h, c) = self.lstm(\n",
    "                embeddings.reshape(seq_len, batch_size, self.embedding_size),\n",
    "                (h, c)\n",
    "        )\n",
    "        \n",
    "        #Use linear mapping to map LSTM outputs to character predictions\n",
    "        outputs = self.linear(torch.squeeze(outputs))\n",
    "\n",
    "        #Return outputs and final state\n",
    "        return outputs, (h, c)\n",
    "\n",
    "\n",
    "    def get_initial_hc(self, batch_size):\n",
    "\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                torch.zeros(1, batch_size, self.hidden_size))\n",
    "\n",
    "\n",
    "    def generate(self, initial_token=' ', num_tokens=100, temperature=1):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #Index of current character initialized to initial character\n",
    "            token = torch.LongTensor([char2idx[initial_token]])\n",
    "            #state of LSTM initialized to all ones\n",
    "            h, c = self.get_initial_hc(1)\n",
    "            #To contain predicted characters in a list\n",
    "            chars = []\n",
    "            \n",
    "            for _ in range(num_tokens):\n",
    "                \n",
    "                #Add current character to list\n",
    "                chars.append(idx2char[token.item()])\n",
    "                \n",
    "                #Use embedding of current character as input\n",
    "                inp = self.embedding(token)\n",
    "                \n",
    "                #Pass current embedding through LSTM and get output and new state\n",
    "                out, (h, c) = self.lstm(inp.reshape(1, 1, self.embedding_size), (h, c))\n",
    "                \n",
    "                #Distribution of possible character predictions based on output\n",
    "                dist = self.linear(out.reshape(1, -1))\n",
    "                \n",
    "                #Temperature controls variation of distribution.  High temperature implies\n",
    "                #likely characters are made more likely.  Low temperature increases chances\n",
    "                #of less likely characters\n",
    "                dist = dist.data.view(-1).div(temperature).exp()\n",
    "                \n",
    "                #Sample character from distribution\n",
    "                chosen_i = torch.multinomial(dist, 1)[0]\n",
    "                \n",
    "                #Update current character\n",
    "                token = torch.LongTensor([chosen_i])\n",
    "                \n",
    "            #Join elements of list into single string    \n",
    "            return ''.join(chars[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of this model takes a long time\n",
    "#For Demo we will used pretrained weights\n",
    "EPOCHS = 500\n",
    "LR = 0.1\n",
    "BETA = 0.8\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "USE_PRETRAINED = True\n",
    "\n",
    "net = ShakespeareGenerator(EMBEDDING_SIZE, HIDDEN_SIZE).float()\n",
    "\n",
    "#Softmax Cross Entropy Loss used \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=BETA)\n",
    "\n",
    "if USE_PRETRAINED:\n",
    "    net.load_state_dict(torch.load('shakespeare.pt', map_location=lambda storage, loc: storage))\n",
    "    \n",
    "else:\n",
    "    for _ in range(EPOCHS):\n",
    "\n",
    "        output, _ = net(X.transpose(0, 1))\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        loss = criterion(output.reshape(-1, NUM_CHARS), Y.reshape(-1))\n",
    "\n",
    "        print(loss.item())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HESER SIVENRY:\n",
      "Asse.\n",
      "\n",
      "QUEEN ELIA:\n",
      "Who nacles, lews a hawnce rowse, I will mine news.\n",
      "\n",
      "GLOUCESTER:\n",
      "I, bid, of my your wooure still break I will\n",
      "non.\n",
      "\n",
      "AUFESAUMERMILAUEN:\n",
      "The can a but rapharoun!\n",
      "As tor,\n",
      "When het he from repeptlemans cries doth palthose I\n",
      "In his kneed never advoo.\n",
      "If poss'd hantay, say, Pomar?\n",
      "Now,\n",
      "The so.\n",
      "\n",
      "Peder for my chame hay the readed:\n",
      "I heques which give hous! Sharance, thee he as your dut under of to dangidl! poss\n",
      "I ckions, heefmed seady mine.-\n",
      "Oxford my coussinion, of the sop shose itses.\n",
      "The and a readed sacy, and\n",
      "'The woinge the are adven of a foot thorred;\n",
      "God-Harny'd will pread privioes, time say, sheep rect your did made.\n",
      "\n",
      "DUKE\n",
      "Haruntruconqupias if igeth than forberve\n",
      "And be's mine osablandect all city and as unne\n",
      "Bear beent.\n",
      "\n",
      "Third, when to God,\n",
      "And we now, stazed.\n",
      "\n",
      "SICINIUS:\n",
      "Poaten just and now.\n",
      "\n",
      "KING HENRY VI:\n",
      "Romeongs,\n",
      "The lord, that not thou\n",
      "ecous one.\n",
      "\n",
      "Sray to\n",
      "alied,\n",
      "The let with and that for by forrHarciince unteen. Ford, thee hithall I parttherse, p\n"
     ]
    }
   ],
   "source": [
    "#Temperature=1 Probability Distribution used as predicted.\n",
    "print(net.generate(temperature=1, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqual;\n",
      "Wheirs!\n",
      "Our let loro! Is; thee heavequil! evenme. Six jut: Geraick, Musimits\n",
      "aticiol.\n",
      "But!'; I natted':\n",
      "UNIO:\n",
      "So of stilling agess Abs, my dades worn,\n",
      "I' am quald;\n",
      "nin; thy horss\n",
      "On makat--\n",
      "Wirmides,\n",
      "Nod, sel esuor\n",
      "s becork!\n",
      "Diss\n",
      "Yarely hearffeth untians,, but penot:\n",
      "Woum gesep? than's quickrent, athas hirst,\n",
      "Nou is osting.\n",
      "Why, ligh hor,\n",
      "Dnors\n",
      "Mell that noth he elful, frurn.\n",
      "Now ish'd tebud, cut yoleest, him,\n",
      "Felpex will, uld's, ose 't I it, thy fion terxmisder,\n",
      "Clounmatiou, 'tioumins bah!\n",
      "\n",
      "GLOUCIO:\n",
      "Alan's: Buere's favy.\n",
      "\n",
      "NUUHELIZAUMONEISORWBINSAUNE:\n",
      "Hayour say:\n",
      "If wiscence, wa, Jo!\n",
      "Their ary!\n",
      "wrock other! Towe. Mel gitter we liays;\n",
      "Dine\n",
      "That whern no\n",
      "pll,\n",
      "Not, past of raice\n",
      "Ally sistety, both:\n",
      "Apt I evesttacollewaiim;\n",
      "For hikers, Has be you dat; gear meefat with buiding is main hermioublootuwn, her? I me; Your-Wa litlanged\n",
      "His or my parm beef?\n",
      "Gabity,-nike\n",
      "I', yiliomes\n",
      "Upon affair-luck, nevish prick'! KAMINA:\n",
      "3 griecure your hals I vive no gepmending. Yet sink'd\n",
      "Get not muter\n"
     ]
    }
   ],
   "source": [
    "#Temperature=1.5 more likely characters are used more often\n",
    "print(net.generate(temperature=1.5, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my shall the singer a shall the so man the seemence the man the grace the shall to the lords, be the countress and the son the so pardess the the say, the shall the words the so see the the shall be me the so present the sea the distinger death and the sea the prise and the with the shall the so be the soldies the see the his we will me the say the sea the seemence the father, the lords and the stream the see with the so man the seen the sea the be with the shall shall the son the sea the and the promised the father in the so man the shall the see the so strease he will the singer to the present the seemen of the will in the so strength the see a do the heart a so to the see the death the sea the man the live the heart the see the sea the heart you the sea the do the heart and the heart you the live my child the sea the sea the so the lords and a sea the shall the death the sea the wars the live he hath the look the see the come a pray and the son, the grace the sea the souly the so m\n"
     ]
    }
   ],
   "source": [
    "#Temperature=0.25 Less likely characters are used more often.\n",
    "print(net.generate(temperature=0.25, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
